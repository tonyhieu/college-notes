---
layout: post
description: COMPSCI 163
categories: [cs163, lecture, winter25, markdown]
title: Graph Algorithms
use-math: true
toc: true
---

## Graph Representation

Want the following out of a graph data structure:
    - Count vertices: O(1)
    - Iterate through all vertices: O(1) per vertex
    - Associate information with vertices: O(1) per get/set
    - Iterate through all edges: O(1) per edge
    - Get degree of vertex: O(1)
    - Count all edges: O(1)
    - Iterate through edges in/out of a vertex: O(1) per edge
    - Associate information with edges: O(1) per get/set
    - Test whether two vertices are connected by an edge: O(1)

### Decorator Pattern and Adjacency Lists

Possible solutions:


1. Dictionary, with vertices as keys
2. Number vertices and index an array using those numbers
3. Separate variables for vertex objects for each piece of information
4. One dictionary variable per vertex with keys for each piece of information

- An **adjacency list** uses a dictionary of vertices as keys and the list of outgoing neighbors as values
    - There are lots of different variations on this structure; different objects for vertices and edges
- The Python-style dictionary representation satisfies the time constraints needed for an efficient PageRank algorithm
    - Some operations are not supported; e.g. looping through incoming edges can be slow

## BFS/DFS

- **Implicit graph**: A graph whose edges and vertices are not already given and must be found through an algorithm (like BFS)
- A **path** is an alternating sequence of endpoints and edges that does not allow repetition
- A **walk** is the same as a path but allows repetition
- **Reachability**: Does there exist a path between two nodes? If so, then they are reachable from each other


## Minimum Spanning Trees
- Given an undirected graph, find a tree that connects all vertices and minimizes the total weight
- Disconnected graphs will output a **spanning forest** as opposed to a tree
- Minimize and maximize are the same problem; simply make weights negative

### Applications

- Build an optimal power grid/transportation routes with minimal total construction cost
- Build a computer network with maximum badwidth - maximum spanning tree
- The minimum spanning tree has the smallest possible bottle neck out of all trees; maximum has the largest

### Properties

- Assumes that there are no "tied" edges, and if they do have the same edge, then use a consistent tiebreaking method
- **Cycle property**: If C is a cycle in the original graph G, then the heaviest edge in this cycle cannot be in the MST
    - In other words: If C is any cycle and e is its heaviest edge, then an MST that contains e will not be the MST
- **Cut property**: If we cut the vertices of the graph into any two subsets of vertices X and G - X, and e is the lihtest edge with endpoints in both subsets, then e must be in the MST
    - Can be used to derive algorithms
- **Path property**: For any two vertices x and y, the MST path from x to y has the minimum possible weight for its heaviest edge

### Algorithms

- Most algorithms to find an MST takes O(n log n) time and utilize the cut property
- Algorithms have been found that take close to linear time or expected linear time but randomized 

#### Jarnik's Algorithm (Prim-Dijkstra)

- Start with some vertex S; this will be the start of the MST, named T
- Repeat until T contains all vertices:
    1. Partition the graph into T and G - T
    2. Find the minimum-weight edge e connecting T and G - T
    3. Add e to T (as well as its corresponding vertex)
- Can be implemented via a priority queue
    - Store vertices not yet in T by the weight of the minimum-weight edge that would connect it to T
    - Update the priority queue each time you update T by looping through the edges
- Using a binary heap, all find/remove operations take O(log n) time, so the total time is **O(m log n)** because each edge is looped over twice
- A Fibonacci heap can get this down to O(m + n log n)

#### Kruskal's Algorithm

- Start by creating a forest of one-vertex trees
- Sort the edges by weight
- For each edge, if it connects two different trees, conenct the trees and add the edge to the MST
- O(m log m) for sorting, O(m) to iterate through list; **O(m log m)** total
- Can use the union-find data structure for near-constant lookups of forests

#### Boruvka's Algorithm (Sollin)

- Start by creating a forest of one-vertex trees
- Label vertices by their tree
- While there is more than one tree, find the minimum-weight outgoing edge from each forest
    - Add all of these minimum-weight edges to the T and connect the forests using them
- The number of trees will go down by a factor of 2 or more, so we will do this iteration log n times
- Looping through all m edges per iteration means the runtime is **O(m log n)**

#### Hybrid Algorithm
- Run Boruvka's algorithm until the number of trees is less than or equal to n / log n
- Run Jarnik's algorithm with Fiboniacci heaps, using a priority queue on the trees as opposed to the vertices
- O(m log log n) from Boruvka and O(m) from Jarnik means that the total runtime is O(m log log n) 

## Topological Ordering

- **Topological ordering**: A list of all vertices in G such that, for every edge $x \rightarrow y$, x is before y in the list
- **Topological sorting**: An algorithm to compute a topological ordering
- Graphs that have cycles cannot have a topological ordering
    - Thus, only directed acyclic graphs can have a topological ordering
- Can use a simple greedy algorithm; add vertices with no incoming edges to the ordering, and remove its outgoing edges from the graph
    - If there is ever a point where there are no "ready" vertices but there are still vertices left to process, then there is a cycle
    - To find the cycle: go to a remaining vertex and walk forward until a vertex is repeated; the sequence between the repititions is the cycle

## Shortest and Longest Paths

- Shortest path can found by BFS; longest path is NP-hard because it includes finding a Hamiltonian path
    - When there exists negative paths, then shortest path is NP-hard
- Shortest walk is not possible if the graph has a negative cycle; can keep walking around the cycle and reducing total weight
- For finding shortest paths in directed graphs:
    - If graph is DAG, use topological ordering (O(m))
    - If graph has nonnegative edge lengths, use Dijkstra's (close to linear time)
        - Works on undirected graphs
    - If graph has negative edges but no negative cycle, use Bellman-Ford algorithm (O(mn))
        - Can also detect negative cycles if one exists
    - Bellman-Ford is optimal and can be improved based on recent results
    - Dijkstra's is "universally optimal" for a fixed graph with variable, positive weights

### Critical Path Scheduling (PERT method)
- Input: a project consisting of multiple tasks that take different amounts of time
- Some tasks can be done simultaneously; others rely on earlier tasks to be completed
- Goal: Find a schedule for the tasks that finishes the project in the lowest possible time
    - AKA longest path finder
- Can use an **activity-on-edge** graph; tasks are converted to edges, and vertices are project milestones
    - Constraints are represented by directed edges and have zero weight
    - The **critical path** is the longest path in this graph from start to end and is the minimum possible time for the schedule
    - Assign times to vertices by making sure that the difference between stages is greater than or equal to the length of the edge between them
- To calculate the optimal schedule, we can use a topological ordering
    - Set the path length of the starting vertex to 0
    - Find the largest incoming edge $u\rightarrow v$ and set the path length of v to $L(u) + weight(u \rightarrow v)$
- Can find the smallest incoming edge to get the shortest paths 

### Shortest Path Trees and Relaxation Algorithms

- In graphs without negative cycles, we can generate a tree of shortest paths
- If s is the starting vertex, then other vertices will have parents that are the vertices that come before them in their shortest path
    - e.g. if the shortest path from x to c is $x \rightarrow b \rightarrow c$, then b is a parent of c in the tree
- Input: A graph with edge lengths and a starting vertex
- Output: Tree of shortest paths from s to all other reachable vertices
    - Two decorations per vertex: the parent and distance from start vertex
- General idea: use the two decorations and update them when shorter paths are found
- Invariants
    - D is the length of some path to x that is greater than or equal to the correct value
    - P is the second-to-last vertex on a path of length â‰¤D
- Initialize by setting P(x) = None and D(x) = 0 if the vertex is s; otherwise D(x) = infinity
- For each edge uv, check whether the distance to u + the length of uv is less than the current shortest path for v, then update if so
    - Known as **relaxing** an edge

```
def relax(u, v):
    if D[u] + length(edge uv) < D[v]:
        D[v] = D[u] + length(edge uv)
        P[v] = u
```

- If the graph is a DAG:
    - Simple algorithm is to go through vertices in topological order and relaxing each vertices' edges
    - Total time is O(m)

```
initialize D, P
for v in topological order:
    for incoming edges uv:
        relax(u, v)
```

#### Bellman-Ford Algorithm
- Uses relaxation paradigm and takes O(mn) time

```
initialize D, P
repeat n-1 times:
    for each edge uv in the whole graph:
        relax(u, v)
```

- Can be improved based on ordering of nodes or stopping early; still results in same big O

#### Dijkstra's Algorithm

- Topologically sorts the shortest path tree by sorting vertices by distance
    - Uses a priority queue to order on the fly

```
initialize D, P
make priority queue Q of vertices, prioritized by D[v]
while Q is non-empty:
    find and remove minimum-priority vertex v in Q
    for each edge vw:
        relax(vw)
```

- Takes O(m log n) with a binary heap or O(m + n log n) with a Fibonacci heap

### Changing Weights without Changing Optimum Paths

- We can add another decoration to the edges, a *height* h(x), to reweight the edges
- Each edge has two properties: length and height
    - New length: $l_h(u\rightarrow v) = l(u\rightarrow v) - h(u) + h(v)$
    - Downhill edges have decreased length, uphill edges have increased length
- Heights can eliminate negative edges and allow Dijkstra's to work
    - Can now use Johnson's and Suurballe's algorithm
    - Won't get rid of negative cycles
- Can also change the order of computation
    - A* algorithm uses this fact

#### Johnson's Algorithm

- Input: A graph G with negative edges but not negative cycles
- Output: Shortest paths between all pairs of vertices

1. Add a start vertex s that is connected to all other vertices by zero-weight edges
2. Use Bellman-Ford only once to compute the shortest paths from s to all other vertices
3. Reweight using the absolute value of distance from s as the height (guarantees that all edges are non-negative)
4. Use Dijkstra from each starting vertex in the reweighted graph

- BF takes O(mn), reweighting takes linear time, Dijkstra is run n times; $O(mn + n^2 \text{log } n)$ time

### Suurballe's Algorithm

- Input: A weighted directed graph and two endpoint vertices, s and t
- Output: Find two paths from s to t such that the paths don't share edges and minimize the sum of the length of both
- Can find two shortest paths by finding one shortest path, then adding "reverse" edges with negative weights from the first shortest path
    - If both shortest paths take the same edge, then the edge will be cancelled out

1. Use Dijkstra to find single-source paths and distances from s
2. Reweight the edges if they belong to a shortest path to equal 0
3. Find shortest path P from s to t and reverse its edges
4. Find a new shortest path in the modified graph
5. Remove any edges visited in both paths and reconnect the paths

- Two runs of Dijkstra, linear time to reweight and reverse; total runtime of O(m + log n)

### A*

- Want to traverse paths to destination with Dijkstra without going down bad paths
- Idea: choose a height function for each vertex v that is easily to calculate and accurately estimates the distance from v to t
    - Must be an underestimate so paths to t eventually go downhill
    - Can't decrease too quickly; height between two vertices differs by at most the length of the edge between them
    - AKA needs to be admissible
- Reweight the graph by height function
    - Edges will be non-negative because of our height function
    - Edges with smaller estimates appear shorter
- Run Dijkstra on this reweighted graph
    - Same runtime as Dijkstra, but with linear time added to reweight