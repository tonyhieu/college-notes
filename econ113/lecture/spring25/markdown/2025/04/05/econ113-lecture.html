<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Game Theory of Human Cooperation and Morality | Anthony Vo’s College Notes</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Game Theory of Human Cooperation and Morality" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="ECON 113" />
<meta property="og:description" content="ECON 113" />
<link rel="canonical" href="https://tonyhieu.github.io/college-notes/econ113/lecture/spring25/markdown/2025/04/05/econ113-lecture.html" />
<meta property="og:url" content="https://tonyhieu.github.io/college-notes/econ113/lecture/spring25/markdown/2025/04/05/econ113-lecture.html" />
<meta property="og:site_name" content="Anthony Vo’s College Notes" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-04-05T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Game Theory of Human Cooperation and Morality" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-04-05T00:00:00-05:00","datePublished":"2025-04-05T00:00:00-05:00","description":"ECON 113","headline":"Game Theory of Human Cooperation and Morality","mainEntityOfPage":{"@type":"WebPage","@id":"https://tonyhieu.github.io/college-notes/econ113/lecture/spring25/markdown/2025/04/05/econ113-lecture.html"},"url":"https://tonyhieu.github.io/college-notes/econ113/lecture/spring25/markdown/2025/04/05/econ113-lecture.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/college-notes/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://tonyhieu.github.io/college-notes/feed.xml" title="Anthony Vo's College Notes" /><link rel="shortcut icon" type="image/x-icon" href="/college-notes/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper">
    <a class="site-title" rel="author" href="/college-notes/">Anthony Vo&#39;s College Notes</a>
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon"></span>
        </label>

        <div class="nav-items">
  <a class="nav-item" href="/college-notes/schedule/">Class Schedule</a>
  <a class="nav-item" href="/college-notes/labs/">Labs</a>
  <a class="nav-item" href="/college-notes/categories/">Tags</a>
  <a class="nav-item" href="/college-notes/search/">Search</a>
</div>

      </nav>
  </div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Game Theory of Human Cooperation and Morality</h1><p class="page-description">ECON 113</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2025-04-05T00:00:00-05:00" itemprop="datePublished">
        Apr 5, 2025
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      13 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/college-notes/categories/#econ113">econ113</a>
        &nbsp;
      
        <a class="category-tags-link" href="/college-notes/categories/#lecture">lecture</a>
        &nbsp;
      
        <a class="category-tags-link" href="/college-notes/categories/#spring25">spring25</a>
        &nbsp;
      
        <a class="category-tags-link" href="/college-notes/categories/#markdown">markdown</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#unit-1">Unit 1</a>
<ul>
<li class="toc-entry toc-h2"><a href="#introduction">Introduction</a></li>
<li class="toc-entry toc-h2"><a href="#course-goals">Course Goals</a>
<ul>
<li class="toc-entry toc-h3"><a href="#10-precepts">10 Precepts</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#games-and-notation">Games and Notation</a></li>
<li class="toc-entry toc-h2"><a href="#social-dillemas">Social Dillemas</a>
<ul>
<li class="toc-entry toc-h3"><a href="#public-good-game">Public Good Game</a></li>
<li class="toc-entry toc-h3"><a href="#tragedy-of-the-commons">Tragedy of the Commons</a></li>
<li class="toc-entry toc-h3"><a href="#contests">Contests</a>
<ul>
<li class="toc-entry toc-h4"><a href="#chicken-game">Chicken Game</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#stag-hunt-game">Stag Hunt Game</a></li>
</ul>
</li>
</ul>
</li>
</ul><h1 id="unit-1">
<a class="anchor" href="#unit-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Unit 1</h1>

<h2 id="introduction">
<a class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h2>
<ul>
  <li>Human life is competitive
    <ul>
      <li>Job market, romance, toys, etc.</li>
      <li>Leads to social conflict</li>
    </ul>
  </li>
  <li>Darwin provided a framework for copmetition
    <ul>
      <li>Individuals inherit different traits, and there are limited resources</li>
      <li>Some traits are better for capturing resources - leads to evolution through <em>natural selection</em>
</li>
    </ul>
  </li>
  <li>Human life is also cooperative
    <ul>
      <li>People work together, shop together, line up together, drive together, etc.</li>
      <li>Humans are more cooperative than chimpanzees; fights over food, strangers are killed
        <ul>
          <li>Chimpanzees are the closest genetic relatives to humans; common ancestor was 6-7 million years ago</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Cooperation is puzzling
    <ul>
      <li>Helping others can give others advantages and reduce your own chance of success</li>
      <li>Despite there being many opportunities for people to be selfish, they don’t take them</li>
      <li>Seems difficult to explain</li>
    </ul>
  </li>
  <li>
<strong>Morality</strong> refers to the standards used to influence and judge decisions
    <ul>
      <li>Acts as a duty to prevent against being selfish</li>
      <li>Constrains individual decision making</li>
      <li>Can have cooperation with and without morality</li>
      <li>Morality includes giving to others at a direct cost to yourself
        <ul>
          <li>On the other hand, cooperation is working together with others and providing resources to gain the return from everyone’s work</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Humans are the only (observed) species with morality
    <ul>
      <li>Other species have forms of cooperation; ant, chimpanzees</li>
      <li>Human parents teach children morals, allowed for by speech and advanced cognitive abilities</li>
      <li>
<em>Utilitarian consequentialism</em>: The right action is the one that produces the most good for the most people</li>
      <li>
<em>Deontological ethcis</em>: Actions should conform with behaviors that serve as universal laws</li>
      <li>Darwin showed that all humans blush - suggests that shame is universal and morality came about long ago in humankind’s evolutionary past</li>
    </ul>
  </li>
  <li>Morality seems to be contradictory to natural selection
    <ul>
      <li>Selfishness increases your chance of survival, so selfish people should have an advantage</li>
      <li>The <strong>puzzle of morality</strong> is that humans are moral despite natural selection seemingly going against morality</li>
    </ul>
  </li>
  <li>Millions of years ago, we used to live in a dominance hierarchy
    <ul>
      <li>
<strong>Dominance hierarchy</strong>: Individuals are ranked highest to lowest; higher-ranked people use their strength to control access to food and mating opportunities, and lower-ranked people must wait</li>
      <li>Hinders cooperation since long-term research and production is disincentivized due to bullies being able to take away from lower-ranked individual</li>
    </ul>
  </li>
  <li>Homo Sapiens lived in a <strong>reversed dominance hierarchy</strong>
    <ul>
      <li>Bullies were policed and suppressed by group members (without formal police and courts)</li>
      <li>Homo Sapiens were more cooperative than modern apes; food sharing, hunting game, supporting children and the injured</li>
      <li>New cooperation is possible due to protection; can hunt more nutritious game and males are more likely to invest in their children due to more monogamy</li>
      <li>Other Homo species had the reversed dominance hierarchy</li>
    </ul>
  </li>
  <li>Hominin species evolved to become bipedal, less conflict (for mates), stone tools, weapons</li>
</ul>

<h2 id="course-goals">
<a class="anchor" href="#course-goals" aria-hidden="true"><span class="octicon octicon-link"></span></a>Course Goals</h2>

<ul>
  <li>Study of proximate causes and ultimate causes
    <ul>
      <li>
<strong>Proximate causes</strong> are immediately responsible for some behavior or event
        <ul>
          <li>Individual level, e.g. an individuals preferences and beliefs</li>
        </ul>
      </li>
      <li>
<strong>Ultimate causes</strong> are deeper forces that explain proximate causes
        <ul>
          <li>Population level, result of evolutionary processes
            <ol>
              <li>Is it instrumentally rational to be cooperative?</li>
            </ol>
          </li>
        </ul>
      </li>
      <li>
<strong>Instrumental</strong>: Acting intentionally to achieve certain outcomes</li>
      <li>Only outcomes matter
        <ol>
          <li>Why are humans so cooperative compared to our closest cousin species?</li>
        </ol>
      </li>
      <li>Two key proximate forces: <strong>Cooperative dispositions and morality</strong> and <strong>advanced cognitive abilities</strong>
</li>
      <li>Humans are able to predict others’ actions, reflect on their decisions, and discuss morals</li>
      <li>Leads to suppression of bullies in hunter-gatherer groups and law in modern times
        <ol>
          <li>How did human cooperation and morality evolve?</li>
        </ol>
      </li>
      <li>Evolutionary pressures led to changes along the hominin line</li>
      <li>Advances in cooperation and morality allowed for selection of cognitive ability and morality</li>
    </ul>
  </li>
  <li>Game theory provides tools to study cooperation and morality
    <ul>
      <li>Classical game theory explains proximate causes, evolutionary game theory explains ultimate causes</li>
      <li>Will study rational deliberation, reciprocity in repreated interaction, assortative matching, in-group favoritism, group selection</li>
    </ul>
  </li>
  <li>Proximate question: Why are humans so cooperative?</li>
  <li>Ultimate question: Why did humans become so cooperative?</li>
</ul>

<h3 id="10-precepts">
<a class="anchor" href="#10-precepts" aria-hidden="true"><span class="octicon octicon-link"></span></a>10 Precepts</h3>

<ol>
  <li>Humans manifest unique and puzzling forms of cooperation and morality</li>
  <li>Cooperation and morality can be studied using game theory</li>
  <li>Selfish motivations generate social dilemmas in which individual actions undermine social welfare</li>
  <li>
<em>Homo Economicus</em> can achieve self-enforcing cooperation using rewards and threats with a sufficient chance of future interaction
    <ul>
      <li>
<em>Homo Economicus</em> is the representation of a selfish, rational human</li>
    </ul>
  </li>
  <li>Self-enforcing cooperation in repeated interaction among <em>Homo Economicus</em> extends to settings with indirect reciprocity, exclusion, and imperfect monitoring</li>
  <li>Human behavior is better represented by <em>Homo Normist</em> than <em>Homo Economicus</em> because it balances conditional rule following and selfishness
    <ul>
      <li>
<em>Homo Normist</em> is a conditional norm follower; they will follow rules if others will</li>
    </ul>
  </li>
  <li>Norm following cannot be explained by consequentialism
    <ul>
      <li>Norm followers must care about rules, not just outcomes</li>
    </ul>
  </li>
  <li>Evolution can select for norm-following preferences and conditionally-cooperative norms</li>
  <li>Positive assortative matching generates a strong evolutionary advantage for cooperators</li>
  <li>Evolutionary selection favors norms of in-group favoritism and highly-cooperative groups in group competition</li>
</ol>

<h2 id="games-and-notation">
<a class="anchor" href="#games-and-notation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Games and Notation</h2>

<ul>
  <li>Basic game: <strong>Prisoner’s Dilemma</strong>
    <ul>
      <li>Highlights Puzzle of Cooperation due to players being disincentivized to cooperate; Nash equilibrium is Pareto inefficient</li>
      <li>Games are <strong>strategic situations</strong>: multi-person, interactive-decision setting where one individual’s actions affect another’s well-being</li>
    </ul>
  </li>
  <li>
<strong>Normal (Strategic) Form</strong>: Describes a game using three things
    <ul>
      <li>A set of individuals (players)</li>
      <li>A set of actions (strategies) for each player</li>
      <li>Player’s preference over outcomes resulting from the choices</li>
      <li>A <strong>game matrix</strong> captures all three parts
        <ul>
          <li>Limited in scope; impossible to represent games with infinite choices</li>
        </ul>
      </li>
      <li>The Nash equilibrium occurs when all actors have a best response in the same cell of the game matrix</li>
      <li>Normal-form games are <em>one-shot</em> games where players choose their strategy and follow through with it</li>
    </ul>
  </li>
  <li>Notation for a normal form game
    <ul>
      <li>Set of players: $I = {1, 2, \ldots, n}$</li>
      <li>Player $i$ chooses a strategy $s_i$ from a set of strategies $S_i$</li>
      <li>Each player $i$ has a utility $u_i(s)\in \mathbb{R}$ for each ${s = (s_1, s_2, \ldots, s_n)}$ from ${S=S_1 \times \ldots \times S_n}$</li>
      <li>Shorthand for $s$: $s = (s_i, s_{-i})$, where $-i$ represents all players other than $i$</li>
    </ul>
  </li>
  <li>Game theory assumes that invidiuals act rationally
    <ul>
      <li>Well-defined goals, well-defined utility function</li>
      <li>Rational agents is known as a <strong>methodological assumption</strong> used to study human behavior</li>
      <li>There are <em>rational preferences</em> (consistent choices) and <em>rational beliefs</em> (evidence-based beliefs)</li>
      <li>Behavior can be <strong>instrumental</strong> or <strong>non-instrumental</strong>, <strong>selfish</strong> or <strong>unselfish</strong>
        <ul>
          <li>
<strong>Homo Economicus</strong> is the main model for agents; they are instrumental and selfish, or intentional, consequential, and selfish</li>
          <li>Some actors might not be Homo Economicus, but they will always be assumed to be rational</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
<strong>Pure strategies</strong> are strategies that are selected at the beginning and followed without deviation; nonrandom</li>
  <li>
<strong>Mixed strategies</strong> are strategies in which players “mix” over pure strategies, choosing pure strategies with random probabilities
    <ul>
      <li>Denoted as $\sigma_i$; if $S_i = {s_{i1}, \ldots, s_{im}}$, then $\sigma_i = (p_{i1},\ldots,p_{im})$, where $p_{ij}$ is the probability that player $i$ chooses strategy $j$</li>
      <li>$\sum_j p_{ij} = 1$</li>
      <li>Pure strategies can be thought of as a subset of a mixed strategy where all probabilities (except for one) are set to 0</li>
    </ul>
  </li>
  <li>
<strong>Von Neumann Morgenstern preferences</strong> state that rational players maximize their expected utility
    <ul>
      <li>The best mixed strategy maximizes the expected utility; assumes that mixed strategies are independent from each other</li>
      <li>Expected utilities require cardinal utilities</li>
    </ul>
  </li>
  <li>
<strong>Solutions</strong> in games are special strategies
    <ul>
      <li>Predicts what will be played</li>
      <li>Empirically valid; played in reality</li>
      <li>Mathematically salient; has special properties
        <ul>
          <li>Defined by a <strong>solution concept</strong> that has mathematical criteria</li>
          <li>There are different solution concepts used for different games</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>The <strong>best response (BR)</strong> for an individual is defined as $s_i^<em>$ such that ${u_i(s^</em><em>i, s</em>{-1})\geq u_i(s’<em>i, s</em>{-1}), \forall s_i’\in S_i \backslash s_i^*}$
    <ul>
      <li>Solutions in classical game theory assumes that individuals play best responses</li>
      <li>BRs can vary based on other players’ strategies</li>
    </ul>
  </li>
  <li>A strategy <strong>strictly dominates</strong> another strategy if the utility for the dominating strategy is always better than the utility for the dominated strategy
    <ul>
      <li>A strictly dominant strategy is defined as ${u_i(s^<em>_i, s_{-1}) &gt; u_i(s’_i, s_{-1}), \forall s_i’\in S_i \backslash s_i^</em>}$</li>
      <li>A strictly dominated strategy is defined as ${\exist s’<em>i\in S_i \text{ s.t. } u_i(s^*_i, s</em>{-1}) &lt; u_i(s’<em>i, s</em>{-1}),}$</li>
      <li>A <strong>dominant-strategy</strong> solution is when all players have a dominant strategy</li>
    </ul>
  </li>
  <li>
<strong>Iterative Elimnation of Dominated Strategies (IEDS)</strong> is a strategy to find solutions to games
    <ol>
      <li>Find dominated strategies</li>
      <li>Remove them from the pool of options, as they should never be chosen</li>
      <li>Repeat steps 1 and 2 until there are no more dominated strategies</li>
    </ol>
  </li>
  <li>A game is <strong>dominance solvable</strong> if IEDS yields a single strategy profile</li>
  <li>IEDS requires <strong>Common Knowledge of the Game (CKG)</strong>: all players know the structure of the game, and all players know that all other players know the structure of the game
    <ul>
      <li>CKG is always assumed</li>
    </ul>
  </li>
  <li>
<strong>Common Knowledge of Rationality</strong>: Each player knows that other players choose best responses, and all players know that all others know that others choose best responses
    <ul>
      <li>Without CKR, players are unsure if dominated strategies will be elimated</li>
    </ul>
  </li>
  <li>CKR and CKG are <em>higher-order beliefs</em>
</li>
  <li>A strategy profile $s^<em>$ is a <strong>(pure) Nash Equilibrium (NE)</strong> if ${\forall i\in I, s’_i\in S_i\backslash s^</em><em>i, u_i(s^*_i, s^*</em>{-i})\geq u_i(s’<em>i, s^*</em>{-i})}$
    <ul>
      <li>A NE is a strategy profile with mutual BRs; everyone is playing a best response</li>
      <li>Games can have 0 to many NE, and some games can have non-pure NE with mixed strategies</li>
      <li>A dominant-strategy solution must be a NE, but not every NE is a dominant-strategy solution</li>
      <li>NE properties
        <ul>
          <li>Each player is a rational actor choosing a BR</li>
          <li>NE can be reached using IEDS</li>
          <li>Players in a NE do not have deep regret</li>
          <li>Different processes can lead to NE</li>
          <li>Nash proved that all solutions have an NE, either mixed or pure</li>
          <li>NE has predictive power</li>
        </ul>
      </li>
      <li>NE shortcomings
        <ul>
          <li>Might only have mixed NE</li>
          <li>Must choose one NE; <strong>equilibrium sleection</strong>
</li>
          <li>Instrumental players must have correct beliefs about others’ strategies
            <ul>
              <li>This means that experimentally, people do not reach NE</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>A mixed-strategy profile $\sigma^<em>$ is a <strong>Mixed Nash Equilibrium</strong> iff ${\forall i\in I, \sigma’_i \in \Delta(S_i)\backslash \sigma_i^</em>, u_i(\sigma^<em>_i, \sigma^</em><em>{-i}) \geq u_i(\sigma’_i, \sigma^*</em>{-i})}$
    <ul>
      <li>Players should only mix over two strategies if they give the same expected utility; use this fact to find the mixed NE</li>
      <li>A mixed NE can dominate a pure NE, allowing for IEDS</li>
    </ul>
  </li>
</ul>

<h2 id="social-dillemas">
<a class="anchor" href="#social-dillemas" aria-hidden="true"><span class="octicon octicon-link"></span></a>Social Dillemas</h2>

<ul>
  <li>
<strong>Social dilemmas</strong> are social interactions (games) in which individual incentives result in an inferior social outcome for the players (Pareto inefficient)</li>
  <li>Games like the Pure Coordination Game have no conflicts of interest for either player; both gain utility simultaneously</li>
  <li>Games like the Matching Pennies Games have a pure conflict of interest; for one player to gain utility, the other has to lose utility</li>
  <li>Games like the Prisoner’s Dilemma has both coordination and conflict; represents a social dilemma
    <ul>
      <li>Can also be thought as a <em>mixed-motive</em> game; players have an incentive to ciirdubate abd move towards an efficient optimum, but once there, they also have an incentive to shirk</li>
    </ul>
  </li>
</ul>

<h3 id="public-good-game">
<a class="anchor" href="#public-good-game" aria-hidden="true"><span class="octicon octicon-link"></span></a>Public Good Game</h3>

<ul>
  <li>Set of players $I = {1, 2, \ldots, n}$</li>
  <li>Each player chooses $s_i \in S_i \text{ s.t. } S_i = [0, \bar{s}]$</li>
  <li>Each player has a utility function $u_i = m\sum_{j\in I}s_j + (\bar{s}-s_i)$
    <ul>
      <li>Can be thought of as the marginal returns to the total contributions plus the player’s remaining budget</li>
      <li>Can be rewritten as $u_i = m\sum_{j\neq I}s_j + \bar{s} - (1-m) s_i$</li>
    </ul>
  </li>
  <li>Each player’s best response is to set $s^*_i = 0$, as an increase to $s_i$ decreases $u_i$
    <ul>
      <li>Total social utility in the NE is $U^* = n\bar{s}$</li>
    </ul>
  </li>
  <li>The social optimum comes from each player choosing $s_i=s$, making the total social utility $U = \sum (m\sum s + (\bar{s} - s)) = n(mn-1)s + n\bar{s}$
    <ul>
      <li>$U$ is increasing in $s$ if $n(mn-1)&gt;0 \rightarrow m&gt;\frac{1}{n}$</li>
      <li>If $m&gt;\frac{1}{n}$, then the social optimal strategy is to contribute $\bar{s}$, making the social optimal utility $mn^2\bar{s}$, much larger than the NE social utility</li>
    </ul>
  </li>
  <li>Main issue is the <strong>free-rider problem</strong>; the individual marginal return is lower than the individual marginal cost, so no one is incentivized to contribute</li>
</ul>

<h3 id="tragedy-of-the-commons">
<a class="anchor" href="#tragedy-of-the-commons" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tragedy of the Commons</h3>

<ul>
  <li>Has two players and a common property of size $y&gt;0$</li>
  <li>Each $i\in I$ chooses how much to consume today (denoted by $c_i\in [0, \frac{y}{2}]$) and then split what is leftover tomorrow to maximize their utility
    <ul>
      <li>$u_i = \ln c_i + \ln(\frac{y-c_i-c_j}{2})$</li>
      <li>The first order condition implies that the BR function is $c_i^* = \frac{y-c_j}{2}$</li>
      <li>NE becomes <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msubsup><mi>c</mi><mn>1</mn><mo>∗</mo></msubsup><mo separator="true">,</mo><msubsup><mi>c</mi><mn>2</mn><mo>∗</mo></msubsup><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mfrac><mi>y</mi><mn>3</mn></mfrac><mo separator="true">,</mo><mfrac><mi>y</mi><mn>3</mn></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(c_1^*, c_2^*) = (\frac{y}{3}, \frac{y}{3})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-2.4519em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-2.4519em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.095em;vertical-align:-0.345em;"></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7475em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7475em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span>
</li>
      <li>Both players consume $\frac{y}{3}$ today and $\frac{y}{6}$ tomorrow</li>
    </ul>
  </li>
  <li>Socially optimal strategy is to consume $\hat{c}_i = \frac{y}{4}$ today; both players consume $\frac{y}{4}$ today and $\frac{y}{4}$ tomorrow
    <ul>
      <li>Better than the NE total social utility</li>
    </ul>
  </li>
  <li>Main issue is the <strong>Tragedy of the Commons</strong>; individuals are incentivized to over-consume today because everyone else will, hurting their utility tomorrow
    <ul>
      <li>Gets worse as more players are added</li>
    </ul>
  </li>
</ul>

<h3 id="contests">
<a class="anchor" href="#contests" aria-hidden="true"><span class="octicon octicon-link"></span></a>Contests</h3>

<ul>
  <li>Two individuals $i\in {1,2}$ and efforts $e_i\in \mathbb{R}^+$</li>
  <li>Probability of winning $p_i(e_i, e_j) = \begin{cases}\frac{e_i}{e_i + e_j}, &amp; e_i + e_j &gt; 0\ \frac{1}{2}, &amp; e_i + e_j = 0\end{cases}$</li>
  <li>Prize value $v&gt;0$</li>
  <li>Utility $u_i = p_i(e_i, e_j)v - e_i$</li>
  <li>BR function: $e_i^* = \sqrt{ve_j} - e_j$
    <ul>
      <li>NE becomes $e_i^* = \frac{v}{4}$</li>
    </ul>
  </li>
  <li>The NE utility for $i$ is $\frac{v}{4}$; the contest intensifies as the prize increases</li>
  <li>The socially optimal solution is to choose $\hat{e}_i = 0$, as the utility for both players will be $\frac{v}{2}$
    <ul>
      <li>Another way to see this is by looking at the prize vs. effort exerted; total prize is $v$, but the contestants exert a total of $\frac{v}{2}$ effort, so they effectively “pay” for half of the prize</li>
    </ul>
  </li>
</ul>

<h4 id="chicken-game">
<a class="anchor" href="#chicken-game" aria-hidden="true"><span class="octicon octicon-link"></span></a>Chicken Game</h4>

<ul>
  <li>Two players decide whether or not to fight one another, can either be a chicken or a fighter</li>
  <li>If both players fight, they both suffer large damage; if neither fights, then they both survive with no loss</li>
  <li>The two pure NE are for one player to fight and another to be a chicken</li>
  <li>Can be thought of as a type of contest where you can either give full effort or none
    <ul>
      <li>Leads to the chicken game also being a coordination game whereas the contest is not</li>
    </ul>
  </li>
</ul>

<h3 id="stag-hunt-game">
<a class="anchor" href="#stag-hunt-game" aria-hidden="true"><span class="octicon octicon-link"></span></a>Stag Hunt Game</h3>
<ul>
  <li>Also known as the Assurance Game</li>
  <li>Basic context: multiple people are hunting a stag, but everyone needs to be focused to kill the stag; if one player goes off to kill a hare, then no one gets the stag (stag gives more utility than hare)
    <ul>
      <li>Coordinating to kill the stag is Pareto optimal, but you can only choose to kill the stag if you have <strong>assurance</strong>, or trust, that the others will also kill the stag</li>
    </ul>
  </li>
  <li>Players will only kill the stag if they payoff for the stag is vastly greater</li>
  <li>Assuming player 2 is playing a mixed strategy, player 1 will choose to kill the stag if and only if $q &gt; \frac{1}{x}$, where $q$ is the chance player 2 will choose $S$ and $x$ is the payoff of $S$</li>
  <li>The <strong>risk-dominant strategy</strong> is to mix and choose $S$ with probability $\frac{1}{x}$</li>
  <li>Risk-averse players will play a <strong>maxmin</strong> strategy (maximizing the minimum payoff), so they will always choose $H$</li>
  <li>Assurance games are social dilemmas due to the lack of assurance</li>
</ul>

  </div><a class="u-url" href="/college-notes/econ113/lecture/spring25/markdown/2025/04/05/econ113-lecture.html" hidden></a>
</article>

      </div>
    </main><link id="fa-stylesheet" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css">

<footer class="site-footer h-card">
  <data class="u-url" value="/college-notes/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
      </div>
      <div class="footer-col">
        <p>Site to document notes for various classes</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
    <a rel="me" href="" target="_blank" title="">
      <span class="grey fa-brands fa- fa-lg"></span>
    </a>
  </li><li>
    <a rel="me" href="" target="_blank" title="">
      <span class="grey fa-brands fa- fa-lg"></span>
    </a>
  </li>
  <li>
    <a href="https://tonyhieu.github.io/college-notes/feed.xml" target="_blank" title="Subscribe to syndication feed">
      <svg class="svg-icon grey" viewbox="0 0 16 16">
        <path d="M12.8 16C12.8 8.978 7.022 3.2 0 3.2V0c8.777 0 16 7.223 16 16h-3.2zM2.194
          11.61c1.21 0 2.195.985 2.195 2.196 0 1.21-.99 2.194-2.2 2.194C.98 16 0 15.017 0
          13.806c0-1.21.983-2.195 2.194-2.195zM10.606
          16h-3.11c0-4.113-3.383-7.497-7.496-7.497v-3.11c5.818 0 10.606 4.79 10.606 10.607z"
        />
      </svg>
    </a>
  </li>
</ul>
</div>

  </div>

</footer>

</body>

</html>
