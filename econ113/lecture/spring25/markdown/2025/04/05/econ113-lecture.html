<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Game Theory of Human Cooperation and Morality | Anthony Vo’s College Notes</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Game Theory of Human Cooperation and Morality" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="ECON 113" />
<meta property="og:description" content="ECON 113" />
<link rel="canonical" href="https://tonyhieu.github.io/college-notes/econ113/lecture/spring25/markdown/2025/04/05/econ113-lecture.html" />
<meta property="og:url" content="https://tonyhieu.github.io/college-notes/econ113/lecture/spring25/markdown/2025/04/05/econ113-lecture.html" />
<meta property="og:site_name" content="Anthony Vo’s College Notes" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-04-05T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Game Theory of Human Cooperation and Morality" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-04-05T00:00:00-05:00","datePublished":"2025-04-05T00:00:00-05:00","description":"ECON 113","headline":"Game Theory of Human Cooperation and Morality","mainEntityOfPage":{"@type":"WebPage","@id":"https://tonyhieu.github.io/college-notes/econ113/lecture/spring25/markdown/2025/04/05/econ113-lecture.html"},"url":"https://tonyhieu.github.io/college-notes/econ113/lecture/spring25/markdown/2025/04/05/econ113-lecture.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/college-notes/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://tonyhieu.github.io/college-notes/feed.xml" title="Anthony Vo's College Notes" /><link rel="shortcut icon" type="image/x-icon" href="/college-notes/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper">
    <a class="site-title" rel="author" href="/college-notes/">Anthony Vo&#39;s College Notes</a>
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon"></span>
        </label>

        <div class="nav-items">
  <a class="nav-item" href="/college-notes/schedule/">Class Schedule</a>
  <a class="nav-item" href="/college-notes/labs/">Labs</a>
  <a class="nav-item" href="/college-notes/categories/">Tags</a>
  <a class="nav-item" href="/college-notes/search/">Search</a>
</div>

      </nav>
  </div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Game Theory of Human Cooperation and Morality</h1><p class="page-description">ECON 113</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2025-04-05T00:00:00-05:00" itemprop="datePublished">
        Apr 5, 2025
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      32 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/college-notes/categories/#econ113">econ113</a>
        &nbsp;
      
        <a class="category-tags-link" href="/college-notes/categories/#lecture">lecture</a>
        &nbsp;
      
        <a class="category-tags-link" href="/college-notes/categories/#spring25">spring25</a>
        &nbsp;
      
        <a class="category-tags-link" href="/college-notes/categories/#markdown">markdown</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#unit-1">Unit 1</a>
<ul>
<li class="toc-entry toc-h2"><a href="#introduction">Introduction</a></li>
<li class="toc-entry toc-h2"><a href="#course-goals">Course Goals</a>
<ul>
<li class="toc-entry toc-h3"><a href="#10-precepts">10 Precepts</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#games-and-notation">Games and Notation</a></li>
<li class="toc-entry toc-h2"><a href="#social-dillemas">Social Dillemas</a>
<ul>
<li class="toc-entry toc-h3"><a href="#public-good-game">Public Good Game</a></li>
<li class="toc-entry toc-h3"><a href="#tragedy-of-the-commons">Tragedy of the Commons</a></li>
<li class="toc-entry toc-h3"><a href="#contests">Contests</a>
<ul>
<li class="toc-entry toc-h4"><a href="#chicken-game">Chicken Game</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#stag-hunt-game">Stag Hunt Game</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#incentivizing-cooperation">Incentivizing Cooperation</a>
<ul>
<li class="toc-entry toc-h3"><a href="#extensive-form-games">Extensive Form Games</a></li>
<li class="toc-entry toc-h3"><a href="#dictator-and-ultimatum-game">Dictator and Ultimatum Game</a></li>
<li class="toc-entry toc-h3"><a href="#repeated-games">Repeated Games</a>
<ul>
<li class="toc-entry toc-h4"><a href="#infinitely-repeated-games">Infinitely Repeated Games</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#unit-2">Unit 2</a>
<ul>
<li class="toc-entry toc-h2"><a href="#experimental-economics">Experimental Economics</a>
<ul>
<li class="toc-entry toc-h3"><a href="#experimental-results">Experimental Results</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#social-norms-and-rule-following">Social Norms and Rule Following</a>
<ul>
<li class="toc-entry toc-h3"><a href="#homo-normist">Homo Normist</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#one-shot-homo-normist-games">One-Shot Homo Normist Games</a>
<ul>
<li class="toc-entry toc-h3"><a href="#general-takeaways">General Takeaways</a></li>
</ul>
</li>
</ul>
</li>
</ul><h1 id="unit-1">
<a class="anchor" href="#unit-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Unit 1</h1>

<h2 id="introduction">
<a class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h2>
<ul>
  <li>Human life is competitive
    <ul>
      <li>Job market, romance, toys, etc.</li>
      <li>Leads to social conflict</li>
    </ul>
  </li>
  <li>Darwin provided a framework for copmetition
    <ul>
      <li>Individuals inherit different traits, and there are limited resources</li>
      <li>Some traits are better for capturing resources - leads to evolution through <em>natural selection</em>
</li>
    </ul>
  </li>
  <li>Human life is also cooperative
    <ul>
      <li>People work together, shop together, line up together, drive together, etc.</li>
      <li>Humans are more cooperative than chimpanzees; fights over food, strangers are killed
        <ul>
          <li>Chimpanzees are the closest genetic relatives to humans; common ancestor was 6-7 million years ago</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Cooperation is puzzling
    <ul>
      <li>Helping others can give others advantages and reduce your own chance of success</li>
      <li>Despite there being many opportunities for people to be selfish, they don’t take them</li>
      <li>Seems difficult to explain</li>
    </ul>
  </li>
  <li>
<strong>Morality</strong> refers to the standards used to influence and judge decisions
    <ul>
      <li>Acts as a duty to prevent against being selfish</li>
      <li>Constrains individual decision making</li>
      <li>Can have cooperation with and without morality</li>
      <li>Morality includes giving to others at a direct cost to yourself
        <ul>
          <li>On the other hand, cooperation is working together with others and providing resources to gain the return from everyone’s work</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Humans are the only (observed) species with morality
    <ul>
      <li>Other species have forms of cooperation; ant, chimpanzees</li>
      <li>Human parents teach children morals, allowed for by speech and advanced cognitive abilities</li>
      <li>
<em>Utilitarian consequentialism</em>: The right action is the one that produces the most good for the most people</li>
      <li>
<em>Deontological ethcis</em>: Actions should conform with behaviors that serve as universal laws</li>
      <li>Darwin showed that all humans blush - suggests that shame is universal and morality came about long ago in humankind’s evolutionary past</li>
    </ul>
  </li>
  <li>Morality seems to be contradictory to natural selection
    <ul>
      <li>Selfishness increases your chance of survival, so selfish people should have an advantage</li>
      <li>The <strong>puzzle of morality</strong> is that humans are moral despite natural selection seemingly going against morality</li>
    </ul>
  </li>
  <li>Millions of years ago, we used to live in a dominance hierarchy
    <ul>
      <li>
<strong>Dominance hierarchy</strong>: Individuals are ranked highest to lowest; higher-ranked people use their strength to control access to food and mating opportunities, and lower-ranked people must wait</li>
      <li>Hinders cooperation since long-term research and production is disincentivized due to bullies being able to take away from lower-ranked individual</li>
    </ul>
  </li>
  <li>Homo Sapiens lived in a <strong>reversed dominance hierarchy</strong>
    <ul>
      <li>Bullies were policed and suppressed by group members (without formal police and courts)</li>
      <li>Homo Sapiens were more cooperative than modern apes; food sharing, hunting game, supporting children and the injured</li>
      <li>New cooperation is possible due to protection; can hunt more nutritious game and males are more likely to invest in their children due to more monogamy</li>
      <li>Other Homo species had the reversed dominance hierarchy</li>
    </ul>
  </li>
  <li>Hominin species evolved to become bipedal, less conflict (for mates), stone tools, weapons</li>
</ul>

<h2 id="course-goals">
<a class="anchor" href="#course-goals" aria-hidden="true"><span class="octicon octicon-link"></span></a>Course Goals</h2>

<ul>
  <li>Study of proximate causes and ultimate causes
    <ul>
      <li>
<strong>Proximate causes</strong> are immediately responsible for some behavior or event
        <ul>
          <li>Individual level, e.g. an individuals preferences and beliefs</li>
        </ul>
      </li>
      <li>
<strong>Ultimate causes</strong> are deeper forces that explain proximate causes
        <ul>
          <li>Population level, result of evolutionary processes
            <ol>
              <li>Is it instrumentally rational to be cooperative?</li>
            </ol>
          </li>
        </ul>
      </li>
      <li>
<strong>Instrumental</strong>: Acting intentionally to achieve certain outcomes</li>
      <li>Only outcomes matter
        <ol>
          <li>Why are humans so cooperative compared to our closest cousin species?</li>
        </ol>
      </li>
      <li>Two key proximate forces: <strong>Cooperative dispositions and morality</strong> and <strong>advanced cognitive abilities</strong>
</li>
      <li>Humans are able to predict others’ actions, reflect on their decisions, and discuss morals</li>
      <li>Leads to suppression of bullies in hunter-gatherer groups and law in modern times
        <ol>
          <li>How did human cooperation and morality evolve?</li>
        </ol>
      </li>
      <li>Evolutionary pressures led to changes along the hominin line</li>
      <li>Advances in cooperation and morality allowed for selection of cognitive ability and morality</li>
    </ul>
  </li>
  <li>Game theory provides tools to study cooperation and morality
    <ul>
      <li>Classical game theory explains proximate causes, evolutionary game theory explains ultimate causes</li>
      <li>Will study rational deliberation, reciprocity in repreated interaction, assortative matching, in-group favoritism, group selection</li>
    </ul>
  </li>
  <li>Proximate question: Why are humans so cooperative?</li>
  <li>Ultimate question: Why did humans become so cooperative?</li>
</ul>

<h3 id="10-precepts">
<a class="anchor" href="#10-precepts" aria-hidden="true"><span class="octicon octicon-link"></span></a>10 Precepts</h3>

<ol>
  <li>Humans manifest unique and puzzling forms of cooperation and morality</li>
  <li>Cooperation and morality can be studied using game theory</li>
  <li>Selfish motivations generate social dilemmas in which individual actions undermine social welfare</li>
  <li>
<em>Homo Economicus</em> can achieve self-enforcing cooperation using rewards and threats with a sufficient chance of future interaction
    <ul>
      <li>
<em>Homo Economicus</em> is the representation of a selfish, rational human</li>
    </ul>
  </li>
  <li>Self-enforcing cooperation in repeated interaction among <em>Homo Economicus</em> extends to settings with indirect reciprocity, exclusion, and imperfect monitoring</li>
  <li>Human behavior is better represented by <em>Homo Normist</em> than <em>Homo Economicus</em> because it balances conditional rule following and selfishness
    <ul>
      <li>
<em>Homo Normist</em> is a conditional norm follower; they will follow rules if others will</li>
    </ul>
  </li>
  <li>Norm following cannot be explained by consequentialism
    <ul>
      <li>Norm followers must care about rules, not just outcomes</li>
    </ul>
  </li>
  <li>Evolution can select for norm-following preferences and conditionally-cooperative norms</li>
  <li>Positive assortative matching generates a strong evolutionary advantage for cooperators</li>
  <li>Evolutionary selection favors norms of in-group favoritism and highly-cooperative groups in group competition</li>
</ol>

<h2 id="games-and-notation">
<a class="anchor" href="#games-and-notation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Games and Notation</h2>

<ul>
  <li>Basic game: <strong>Prisoner’s Dilemma</strong>
    <ul>
      <li>Highlights Puzzle of Cooperation due to players being disincentivized to cooperate; Nash equilibrium is Pareto inefficient</li>
      <li>Games are <strong>strategic situations</strong>: multi-person, interactive-decision setting where one individual’s actions affect another’s well-being</li>
    </ul>
  </li>
  <li>
<strong>Normal (Strategic) Form</strong>: Describes a game using three things
    <ul>
      <li>A set of individuals (players)</li>
      <li>A set of actions (strategies) for each player</li>
      <li>Player’s preference over outcomes resulting from the choices</li>
      <li>A <strong>game matrix</strong> captures all three parts
        <ul>
          <li>Limited in scope; impossible to represent games with infinite choices</li>
        </ul>
      </li>
      <li>The Nash equilibrium occurs when all actors have a best response in the same cell of the game matrix</li>
      <li>Normal-form games are <em>one-shot</em> games where players choose their strategy and follow through with it</li>
    </ul>
  </li>
  <li>Notation for a normal form game
    <ul>
      <li>Set of players: $I = {1, 2, \ldots, n}$</li>
      <li>Player $i$ chooses a strategy $s_i$ from a set of strategies $S_i$</li>
      <li>Each player $i$ has a utility $u_i(s)\in \mathbb{R}$ for each ${s = (s_1, s_2, \ldots, s_n)}$ from ${S=S_1 \times \ldots \times S_n}$</li>
      <li>Shorthand for $s$: $s = (s_i, s_{-i})$, where $-i$ represents all players other than $i$</li>
    </ul>
  </li>
  <li>Game theory assumes that invidiuals act rationally
    <ul>
      <li>Well-defined goals, well-defined utility function</li>
      <li>Rational agents is known as a <strong>methodological assumption</strong> used to study human behavior</li>
      <li>There are <em>rational preferences</em> (consistent choices) and <em>rational beliefs</em> (evidence-based beliefs)</li>
      <li>Behavior can be <strong>instrumental</strong> or <strong>non-instrumental</strong>, <strong>selfish</strong> or <strong>unselfish</strong>
        <ul>
          <li>
<strong>Homo Economicus</strong> is the main model for agents; they are instrumental and selfish, or intentional, consequential, and selfish</li>
          <li>Some actors might not be Homo Economicus, but they will always be assumed to be rational
            <ul>
              <li>Rational actors maximize utility, where utility is defined as some individual material payoff</li>
            </ul>
          </li>
          <li>Hard to achieve cooperation with Homo Economicus; if cooperation is achieved, then it can be achieved in many other situations</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
<strong>Pure strategies</strong> are strategies that are selected at the beginning and followed without deviation; nonrandom</li>
  <li>
<strong>Mixed strategies</strong> are strategies in which players “mix” over pure strategies, choosing pure strategies with random probabilities
    <ul>
      <li>Denoted as $\sigma_i$; if $S_i = {s_{i1}, \ldots, s_{im}}$, then $\sigma_i = (p_{i1},\ldots,p_{im})$, where $p_{ij}$ is the probability that player $i$ chooses strategy $j$</li>
      <li>$\sum_j p_{ij} = 1$</li>
      <li>Pure strategies can be thought of as a subset of a mixed strategy where all probabilities (except for one) are set to 0</li>
    </ul>
  </li>
  <li>
<strong>Von Neumann Morgenstern preferences</strong> state that rational players maximize their expected utility
    <ul>
      <li>The best mixed strategy maximizes the expected utility; assumes that mixed strategies are independent from each other</li>
      <li>Expected utilities require cardinal utilities</li>
    </ul>
  </li>
  <li>
<strong>Solutions</strong> in games are special strategies
    <ul>
      <li>Predicts what will be played</li>
      <li>Empirically valid; played in reality</li>
      <li>Mathematically salient; has special properties
        <ul>
          <li>Defined by a <strong>solution concept</strong> that has mathematical criteria</li>
          <li>There are different solution concepts used for different games</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>The <strong>best response (BR)</strong> for an individual is defined as $s_i^<em>$ such that ${u_i(s^</em><em>i, s</em>{-1})\geq u_i(s’<em>i, s</em>{-1}), \forall s_i’\in S_i \backslash s_i^*}$
    <ul>
      <li>Solutions in classical game theory assumes that individuals play best responses</li>
      <li>BRs can vary based on other players’ strategies</li>
    </ul>
  </li>
  <li>A strategy <strong>strictly dominates</strong> another strategy if the utility for the dominating strategy is always better than the utility for the dominated strategy
    <ul>
      <li>A strictly dominant strategy is defined as ${u_i(s^<em>_i, s_{-1}) &gt; u_i(s’_i, s_{-1}), \forall s_i’\in S_i \backslash s_i^</em>}$</li>
      <li>A strictly dominated strategy is defined as ${\exist s’<em>i\in S_i \text{ s.t. } u_i(s^*_i, s</em>{-1}) &lt; u_i(s’<em>i, s</em>{-1}),}$</li>
      <li>A <strong>dominant-strategy</strong> solution is when all players have a dominant strategy</li>
    </ul>
  </li>
  <li>
<strong>Iterative Elimnation of Dominated Strategies (IEDS)</strong> is a strategy to find solutions to games
    <ol>
      <li>Find dominated strategies</li>
      <li>Remove them from the pool of options, as they should never be chosen</li>
      <li>Repeat steps 1 and 2 until there are no more dominated strategies</li>
    </ol>
  </li>
  <li>A game is <strong>dominance solvable</strong> if IEDS yields a single strategy profile</li>
  <li>IEDS requires <strong>Common Knowledge of the Game (CKG)</strong>: all players know the structure of the game, and all players know that all other players know the structure of the game
    <ul>
      <li>CKG is always assumed</li>
    </ul>
  </li>
  <li>
<strong>Common Knowledge of Rationality</strong>: Each player knows that other players choose best responses, and all players know that all others know that others choose best responses
    <ul>
      <li>Without CKR, players are unsure if dominated strategies will be elimated</li>
    </ul>
  </li>
  <li>CKR and CKG are <em>higher-order beliefs</em>
</li>
  <li>A strategy profile $s^<em>$ is a <strong>(pure) Nash Equilibrium (NE)</strong> if ${\forall i\in I, s’_i\in S_i\backslash s^</em><em>i, u_i(s^*_i, s^*</em>{-i})\geq u_i(s’<em>i, s^*</em>{-i})}$
    <ul>
      <li>A NE is a strategy profile with mutual BRs; everyone is playing a best response</li>
      <li>Games can have 0 to many NE, and some games can have non-pure NE with mixed strategies</li>
      <li>A dominant-strategy solution must be a NE, but not every NE is a dominant-strategy solution</li>
      <li>NE properties
        <ul>
          <li>Each player is a rational actor choosing a BR</li>
          <li>NE can be reached using IEDS</li>
          <li>Players in a NE do not have deep regret</li>
          <li>Different processes can lead to NE</li>
          <li>Nash proved that all solutions have an NE, either mixed or pure</li>
          <li>NE has predictive power</li>
        </ul>
      </li>
      <li>NE shortcomings
        <ul>
          <li>Might only have mixed NE</li>
          <li>Must choose one NE; <strong>equilibrium sleection</strong>
</li>
          <li>Instrumental players must have correct beliefs about others’ strategies
            <ul>
              <li>This means that experimentally, people do not reach NE</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>A mixed-strategy profile $\sigma^<em>$ is a <strong>Mixed Nash Equilibrium</strong> iff ${\forall i\in I, \sigma’_i \in \Delta(S_i)\backslash \sigma_i^</em>, u_i(\sigma^<em>_i, \sigma^</em><em>{-i}) \geq u_i(\sigma’_i, \sigma^*</em>{-i})}$
    <ul>
      <li>Players should only mix over two strategies if they give the same expected utility; use this fact to find the mixed NE</li>
      <li>A mixed NE can dominate a pure NE, allowing for IEDS</li>
    </ul>
  </li>
</ul>

<h2 id="social-dillemas">
<a class="anchor" href="#social-dillemas" aria-hidden="true"><span class="octicon octicon-link"></span></a>Social Dillemas</h2>

<ul>
  <li>
<strong>Social dilemmas</strong> are social interactions (games) in which individual incentives result in an inferior social outcome for the players (Pareto inefficient)</li>
  <li>Games like the Pure Coordination Game have no conflicts of interest for either player; both gain utility simultaneously</li>
  <li>Games like the Matching Pennies Games have a pure conflict of interest; for one player to gain utility, the other has to lose utility</li>
  <li>Games like the Prisoner’s Dilemma has both coordination and conflict; represents a social dilemma
    <ul>
      <li>Can also be thought as a <em>mixed-motive</em> game; players have an incentive to ciirdubate abd move towards an efficient optimum, but once there, they also have an incentive to shirk</li>
    </ul>
  </li>
</ul>

<h3 id="public-good-game">
<a class="anchor" href="#public-good-game" aria-hidden="true"><span class="octicon octicon-link"></span></a>Public Good Game</h3>

<ul>
  <li>Set of players $I = {1, 2, \ldots, n}$</li>
  <li>Each player chooses $s_i \in S_i \text{ s.t. } S_i = [0, \bar{s}]$</li>
  <li>Each player has a utility function $u_i = m\sum_{j\in I}s_j + (\bar{s}-s_i)$
    <ul>
      <li>Can be thought of as the marginal returns to the total contributions plus the player’s remaining budget</li>
      <li>Can be rewritten as $u_i = m\sum_{j\neq I}s_j + \bar{s} - (1-m) s_i$</li>
    </ul>
  </li>
  <li>Each player’s best response is to set $s^*_i = 0$, as an increase to $s_i$ decreases $u_i$
    <ul>
      <li>Total social utility in the NE is $U^* = n\bar{s}$</li>
    </ul>
  </li>
  <li>The social optimum comes from each player choosing $s_i=s$, making the total social utility $U = \sum (m\sum s + (\bar{s} - s)) = n(mn-1)s + n\bar{s}$
    <ul>
      <li>$U$ is increasing in $s$ if $n(mn-1)&gt;0 \rightarrow m&gt;\frac{1}{n}$</li>
      <li>If $m&gt;\frac{1}{n}$, then the social optimal strategy is to contribute $\bar{s}$, making the social optimal utility $mn^2\bar{s}$, much larger than the NE social utility</li>
    </ul>
  </li>
  <li>Main issue is the <strong>free-rider problem</strong>; the individual marginal return is lower than the individual marginal cost, so no one is incentivized to contribute</li>
</ul>

<h3 id="tragedy-of-the-commons">
<a class="anchor" href="#tragedy-of-the-commons" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tragedy of the Commons</h3>

<ul>
  <li>Has two players and a common property of size $y&gt;0$</li>
  <li>Each $i\in I$ chooses how much to consume today (denoted by $c_i\in [0, \frac{y}{2}]$) and then split what is leftover tomorrow to maximize their utility
    <ul>
      <li>$u_i = \ln c_i + \ln(\frac{y-c_i-c_j}{2})$</li>
      <li>The first order condition implies that the BR function is $c_i^* = \frac{y-c_j}{2}$</li>
      <li>NE becomes <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msubsup><mi>c</mi><mn>1</mn><mo>∗</mo></msubsup><mo separator="true">,</mo><msubsup><mi>c</mi><mn>2</mn><mo>∗</mo></msubsup><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mfrac><mi>y</mi><mn>3</mn></mfrac><mo separator="true">,</mo><mfrac><mi>y</mi><mn>3</mn></mfrac><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(c_1^*, c_2^*) = (\frac{y}{3}, \frac{y}{3})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-2.4519em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-2.4519em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.095em;vertical-align:-0.345em;"></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7475em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7475em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span>
</li>
      <li>Both players consume $\frac{y}{3}$ today and $\frac{y}{6}$ tomorrow</li>
    </ul>
  </li>
  <li>Socially optimal strategy is to consume $\hat{c}_i = \frac{y}{4}$ today; both players consume $\frac{y}{4}$ today and $\frac{y}{4}$ tomorrow
    <ul>
      <li>Better than the NE total social utility</li>
    </ul>
  </li>
  <li>Main issue is the <strong>Tragedy of the Commons</strong>; individuals are incentivized to over-consume today because everyone else will, hurting their utility tomorrow
    <ul>
      <li>Gets worse as more players are added</li>
    </ul>
  </li>
</ul>

<h3 id="contests">
<a class="anchor" href="#contests" aria-hidden="true"><span class="octicon octicon-link"></span></a>Contests</h3>

<ul>
  <li>Two individuals $i\in {1,2}$ and efforts $e_i\in \mathbb{R}^+$</li>
  <li>Probability of winning $p_i(e_i, e_j) = \begin{cases}\frac{e_i}{e_i + e_j}, &amp; e_i + e_j &gt; 0\ \frac{1}{2}, &amp; e_i + e_j = 0\end{cases}$</li>
  <li>Prize value $v&gt;0$</li>
  <li>Utility $u_i = p_i(e_i, e_j)v - e_i$</li>
  <li>BR function: $e_i^* = \sqrt{ve_j} - e_j$
    <ul>
      <li>NE becomes $e_i^* = \frac{v}{4}$</li>
    </ul>
  </li>
  <li>The NE utility for $i$ is $\frac{v}{4}$; the contest intensifies as the prize increases</li>
  <li>The socially optimal solution is to choose $\hat{e}_i = 0$, as the utility for both players will be $\frac{v}{2}$
    <ul>
      <li>Another way to see this is by looking at the prize vs. effort exerted; total prize is $v$, but the contestants exert a total of $\frac{v}{2}$ effort, so they effectively “pay” for half of the prize</li>
    </ul>
  </li>
</ul>

<h4 id="chicken-game">
<a class="anchor" href="#chicken-game" aria-hidden="true"><span class="octicon octicon-link"></span></a>Chicken Game</h4>

<ul>
  <li>Two players decide whether or not to fight one another, can either be a chicken or a fighter</li>
  <li>If both players fight, they both suffer large damage; if neither fights, then they both survive with no loss</li>
  <li>The two pure NE are for one player to fight and another to be a chicken</li>
  <li>Can be thought of as a type of contest where you can either give full effort or none
    <ul>
      <li>Leads to the chicken game also being a coordination game whereas the contest is not</li>
    </ul>
  </li>
</ul>

<h3 id="stag-hunt-game">
<a class="anchor" href="#stag-hunt-game" aria-hidden="true"><span class="octicon octicon-link"></span></a>Stag Hunt Game</h3>
<ul>
  <li>Also known as the Assurance Game</li>
  <li>Basic context: multiple people are hunting a stag, but everyone needs to be focused to kill the stag; if one player goes off to kill a hare, then no one gets the stag (stag gives more utility than hare)
    <ul>
      <li>Coordinating to kill the stag is Pareto optimal, but you can only choose to kill the stag if you have <strong>assurance</strong>, or trust, that the others will also kill the stag</li>
    </ul>
  </li>
  <li>Players will only kill the stag if they payoff for the stag is vastly greater</li>
  <li>Assuming player 2 is playing a mixed strategy, player 1 will choose to kill the stag if and only if $q &gt; \frac{1}{x}$, where $q$ is the chance player 2 will choose $S$ and $x$ is the payoff of $S$</li>
  <li>The <strong>risk-dominant strategy</strong> is to mix and choose $S$ with probability $\frac{1}{x}$</li>
  <li>Risk-averse players will play a <strong>maxmin</strong> strategy (maximizing the minimum payoff), so they will always choose $H$</li>
  <li>Assurance games are social dilemmas due to the lack of assurance</li>
</ul>

<h2 id="incentivizing-cooperation">
<a class="anchor" href="#incentivizing-cooperation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Incentivizing Cooperation</h2>

<ul>
  <li>To achieve cooperation, the game itself must be changed (strategy set, players, utility functions)
    <ul>
      <li>Changing the set of players: change the players’ preference (Homo Economicus to Homo Altruist), add players (like police), exclude players</li>
      <li>Changing strategy set: repeat the same interaction, introduce new ways of interacting</li>
      <li>Changing utilities is implied when doing the above actions</li>
      <li>Typically, we will keep Homo Economicus and change other assumptions</li>
    </ul>
  </li>
  <li>
<strong>Reciprocity</strong>: Receiving an action and doing the same action back to the other player
    <ul>
      <li>Requires timing of choices, knowledge of others’ choices, etc.</li>
      <li>We will use an <strong>extensive-form game</strong> to model this</li>
      <li>Reciprocity relies on <strong>history-dependent strategies</strong> where players remember what happened earlier in the game
        <ul>
          <li>
<strong>Trigger strategy</strong>: A strategy where one player instantly punishes the other in response to a non-cooperative behavior</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>History-dependent strategies rely on <strong>monitoring</strong> where players observe other players’ actions
    <ul>
      <li>Better monitoring = more accurate strategies</li>
    </ul>
  </li>
  <li>External third party actors can induce cooperation, typically by using trigger strategies (think of police)
    <ul>
      <li>
<strong>Self-enforcing cooperation</strong> is cooperation without external enforcement; the Puzzle of Cooperation asks why people cooperate without these externalities</li>
      <li>Punishing can be thought of as a public good game since punishment requires resources
        <ul>
          <li>Known as the <strong>Second-order Public Good Problem</strong> since external enforcement is a public good</li>
          <li>This means that external enforcement also requires self-enforcing cooperation due to second-order public good problems</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="extensive-form-games">
<a class="anchor" href="#extensive-form-games" aria-hidden="true"><span class="octicon octicon-link"></span></a>Extensive Form Games</h3>

<ul>
  <li>Sequential games can provide advantages to players arbitrarily based on move order
    <ul>
      <li>Chicken Game has first-mover advantage, Matching Pennies has last-mover advantage, PD has no advantage</li>
    </ul>
  </li>
  <li>
<strong>Dictator Game</strong>: Only one player has an option, meaning that they have a first-mover advanage</li>
  <li>A <strong>game tree</strong> represents sequential actions
    <ul>
      <li>Starts at a decision node, and each decision node has branches that represent possible choices</li>
      <li>Terminal nodes have payoff profiles</li>
      <li>Trees are acyclic</li>
    </ul>
  </li>
  <li>
<strong>Extensive Form Games</strong> include more information than normal form ones
    <ul>
      <li>Set of players</li>
      <li>Order of moves/decisions</li>
      <li>What each player’s possible decisions are at each decision node</li>
      <li>What each player knows about prior moves when making a chioce</li>
      <li>Utilities dependent on moves</li>
      <li>Probability distributions over random events</li>
    </ul>
  </li>
  <li>The extensive form is a complete representation of a game; a normal form is a (useful) abstraction since normal form is a subset</li>
  <li>An <strong>information set</strong> represents what a player knows when making a move
    <ul>
      <li>Represented in a game tree using a circle/oval/rectangle; whatever is outside of the circle is outside of the information set</li>
      <li>Depicted as $\mathcal{I}_i = {{a}, {b, c}, \cdots }$</li>
      <li>A game with <strong>perfect information</strong> means that all information sets have one decision node
        <ul>
          <li>Implicit: simultaneous games cannot have perfect information</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>A <strong>pure strategy</strong> in the extensive form is a complete plan of moves, where one move is planned for each information set
    <ul>
      <li>A pure strategy is chosen at the start of the game and followed throughout, regardless of if an information set is unreachable or not</li>
      <li>A <strong>mixed strategy</strong> is a randomization of pure strategies, just as in normal-form games</li>
    </ul>
  </li>
  <li>
<strong>Sequential rationality</strong>: A rationality where players look ahead and predict future moves; players assume that BRs will be chosen in all future moves
    <ul>
      <li>Sequential rationality is depicted using backward induction (BI) in perfect information games</li>
    </ul>
  </li>
  <li>
<strong>Kuhn’s Theorem</strong>: Every finite extensive-form game of perfect information has a BI solution
    <ul>
      <li>This means that every BI solution has a corresponding weak IEDS NE</li>
    </ul>
  </li>
  <li>BI requires common knowledge of the game, common knowledge of rationality, and a large cognitive load
    <ul>
      <li>Players might not use BI if these requirements are not met</li>
    </ul>
  </li>
  <li>
<strong>Subgames</strong> are studied to solve games with imperfect information
    <ul>
      <li>Subgames start from a single decision node, contains all of the later decision nodes and information sets, and maintains the original information sets</li>
      <li>Can be thought of as a extensive-form game that exists in another extensive-form game</li>
      <li>Each single decision node forms a new subgame; games with imperfect information will have a number of subgames less than the number of decision nodes</li>
    </ul>
  </li>
  <li>A <strong>Subgame Perfect Equilibrium (SPE)</strong> is an equilibrium where each subgame has an NE
    <ul>
      <li>SPEs can be found in a game with imperfect information</li>
      <li>A BI solution is a SPE solution of a perfect-information game</li>
      <li>Caputres sequential rationality</li>
    </ul>
  </li>
</ul>

<h3 id="dictator-and-ultimatum-game">
<a class="anchor" href="#dictator-and-ultimatum-game" aria-hidden="true"><span class="octicon octicon-link"></span></a>Dictator and Ultimatum Game</h3>

<ul>
  <li>Dictator Setup: Player 1 chooses $s_1 \in [0, \bar{s}]$ to give to player 2
    <ul>
      <li>Using Homo Economicus preferences, $u_1 = \bar{s} - s_1$ and $u_2 = s_1$</li>
    </ul>
  </li>
  <li>Player 1 will always choose $s_1^* = 0$</li>
  <li>Ultimatum Setup: Player 1 chooses $s_1 \in [0, \bar{s}]$ to give to player 2, and player 2 must accept the offer
    <ul>
      <li>
        <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>u</mi><mn>1</mn></msub><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mover accent="true"><mi>s</mi><mo>ˉ</mo></mover><mo>−</mo><msub><mi>s</mi><mn>1</mn></msub><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>if player 2 accepts</mtext></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>0</mn><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>if player 2 rejects</mtext></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">u_1 = \begin{cases}\bar{s} - s_1, &amp; \text{if player 2 accepts}\\ 0, &amp; \text{if player 2 rejects}\end{cases}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3em;vertical-align:-1.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em;"><span style="top:-3.69em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.5678em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">s</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord">0</span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em;"><span style="top:-3.69em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord text"><span class="mord">if player 2 accepts</span></span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord text"><span class="mord">if player 2 rejects</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em;"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
      </li>
      <li>
        <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>u</mi><mn>2</mn></msub><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>s</mi><mn>1</mn></msub><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>if player 2 accepts</mtext></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>0</mn><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>if player 2 rejects</mtext></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">u_2 = \begin{cases}s_1, &amp; \text{if player 2 accepts}\\ 0, &amp; \text{if player 2 rejects}\end{cases}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3em;vertical-align:-1.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em;"><span style="top:-3.69em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord">0</span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em;"><span style="top:-3.69em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord text"><span class="mord">if player 2 accepts</span></span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord text"><span class="mord">if player 2 rejects</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em;"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
      </li>
    </ul>
  </li>
  <li>Player 2 will accept any offer since it will be better than or the same as rejection, so player 1 will only choose to share 0</li>
  <li>These games show that Homo Economicus will not share any money in the Dictator Game and will accept any offer in the Ultimatum Game
    <ul>
      <li>No/very little money is shared in both</li>
    </ul>
  </li>
</ul>

<h3 id="repeated-games">
<a class="anchor" href="#repeated-games" aria-hidden="true"><span class="octicon octicon-link"></span></a>Repeated Games</h3>

<ul>
  <li>Many interactions are repeated, and threats of punishments/bad responses in future periods dissuade short-run selfishness</li>
  <li>
<strong>Repeated games</strong> are a subset of extensive-form games
    <ul>
      <li>Involves <strong>stage games</strong> (which is an extensive-form game in of itself) that are played multiple times</li>
      <li>Players observe + remember the moves from each stage</li>
      <li>There are $T$ <strong>stages</strong>, and the utility is the sum of the utilities at each stage (possibly with a discount)</li>
      <li>Not easily represented with a game tree; too large
        <ul>
          <li>Better represented with the stage game and the number of pretitions $T$</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Repeated games can be infinite $(T=\infty)$ or finite
    <ul>
      <li>Finitely repeated games with a unique stage-game NE must have a unique SPE, as backward induction can be used
        <ul>
          <li>Implies that cooperation is not possible since players (Homo Economiucs) will try to be selfish at the last stage (and consequently all stages before that)</li>
        </ul>
      </li>
      <li>If the stage game does not have a unique NE, there will be multiple <em>history-independent</em> SPE
        <ul>
          <li>Not of note; everything is independent, and no reward/punishment strategies are employed</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
<strong>History-dependent</strong> strategies bases future behavior on the past
    <ul>
      <li>
<strong>One shot deviation principle</strong>: A strategy is a BR (and SPE) if there is no benefit to deviating in any singular stage of the game</li>
      <li>The SPEs from history-dependent strategies might not follow the stage game NEs and also can outperform history-independent strategies</li>
      <li>
<strong>Trigger strategies</strong> involve punishing non-cooperative behavior by threatening to be non-cooperative in all future periods
        <ul>
          <li>Will also reward cooperative behavior with future cooperation</li>
          <li>Incentives sacrificing short-term gains for long-term gains</li>
          <li>Requires multiple NE in stage game and rewards/punishment greater than defection gain</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="infinitely-repeated-games">
<a class="anchor" href="#infinitely-repeated-games" aria-hidden="true"><span class="octicon octicon-link"></span></a>Infinitely Repeated Games</h4>

<ul>
  <li>In these games, $T=\infty$
    <ul>
      <li>Does not mean the game will actually go on forever; players simply don’t know when the game will end</li>
    </ul>
  </li>
  <li>Payoffs are <strong>discounted</strong> for future stages since payoff in the future is not realized and thus has less importance than present payoffs
    <ul>
      <li>The <strong>discount factor</strong> is denoted as $0 &lt; \delta &lt; 1$; overall utility is $U_i = \sum^\infty_{t=0}\delta^tu_{it}$
        <ul>
          <li>Short form sum: $U_i = \frac{1-\delta^T}{1-\delta}v = \frac{1}{1-\delta}v$ if $T\rightarrow\infty$</li>
          <li>Discount factor is assumed to be the same across all players</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>A <strong>one-shot deviation</strong> from a strategy $s_i$ is a strategy $s_i’$ where you only deviate in one period
    <ul>
      <li>The <strong>One-Shot Deviation Principle</strong> states that a strategy profile is an SPE iff there are no profitable one-shot deviations</li>
    </ul>
  </li>
  <li>Similar to finite games, history-independent SPE will not induce cooperation since they are only comprised of (selfish) NE
    <ul>
      <li>Must use history-dependent strategies to get cooperation</li>
    </ul>
  </li>
  <li>
<strong>Grim Trigger Strategy</strong>: Keep cooperating until the other player does not cooperate; then, only defect
    <ul>
      <li>Key properties: initial and potentially infinite cooperation, infinite punishment after defection</li>
      <li>Two phases: <strong>cooperation phase</strong> and <strong>punishment phase</strong>, can calculate benefit (and necessary $\delta$ for cooperation) from deviating in the cooperation phase</li>
      <li>Employs <strong>direct reciprocity</strong> to sustain cooepration; works when there is a low punishment payoff and a high discount factor</li>
    </ul>
  </li>
  <li>The Grim Trigger strategy is known as a <strong>Nash-Reversion strategy</strong> because it has a history-dependent phase (cooperation) and a history-independent phase (punishment)
    <ul>
      <li>Nash reversion ensures an SPE since the history-independent period will be guaranteed to be an SPE</li>
      <li>Intuitive; cooperate, and then punish by not cooperating using NE actions</li>
      <li>May require large discount factors, but will always exist</li>
    </ul>
  </li>
  <li>By adding infinite periods, non-cooperative games (like PD) can be turned into coordination games with a cooperation equilibrium</li>
  <li>A <strong>minmax punishment</strong> punishes a player for not cooperating by guaranteeing the defector receives their <strong>minmax utility</strong>; i.e. the minimum utility possible assuming the defector is maximizing their utility
    <ul>
      <li>More extreme than Nash reversion, as the minmax punishment might not be a NE</li>
      <li>Requires a lower discount rate in general due to the harsher punishment, leading to more cooperation</li>
      <li>Might not be a SPE since the punishment because the minmax punishment might not be a NE
        <ul>
          <li>Can be a NE without being a SPE</li>
          <li>Punisher may want to go deviate back to the NE in the stage game if the payoff is higher; makes minmax punishment less credible</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
<strong>Indrect reciprocity</strong> is when a third party reciprocates based on the interactions between two separate players
    <ul>
      <li>Example: Infinitely-Repeated Random-Matching PD, where there are $n\geq 4$ players who are randomly matched with each other
        <ul>
          <li>Direct Grim strategy: Play C when you are paired with someone for the first time, and keep playing C if they palyed C; play D otherwise
            <ul>
              <li>Requires a discount rate of $\delta \geq \frac{n-1}{n}$ since you are unlikely to play the same person multiple times</li>
            </ul>
          </li>
          <li>Indirect Grim strategy: Play C at first, and play C if your partner played C in all prior rounds; play D otherwise
            <ul>
              <li>Requires a discount rate of $\frac{1}{2}$ instead</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Relies on perfect observation and memory, but can still work with imperfections
        <ul>
          <li>Humans rely on communication (gossip) to share information</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Cooperation can be sustained by excluding others
    <ul>
      <li>
<strong>Rivalrous</strong>: A good can only be consumed by one person</li>
      <li>
<strong>Excludable</strong>: A person can be prevented from consuming a good</li>
      <li>
<strong>Club goods</strong> are non-rivalrous, excludable goods that are produced by clubs (families, gyms, church, etc.)</li>
      <li>The threat of being kicked out of a club can incentivize cooperation and leave the punishers even better off</li>
      <li>Requires a relatively low cost compared to the number of members in the club
        <ul>
          <li>If cost is too high, then punishers will go back to the standard Grim strategy</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Cooperation can still be sustained even with <strong>imperfect monitoring</strong> such that not all actions are observed
    <ul>
      <li>Example: The probabilistic Convex Public Good game, where $n’$ of the $n$ players are selected at random and monitored
        <ul>
          <li>Probability of being observed: $m = \frac{n’}{n}$</li>
        </ul>
      </li>
      <li>Discount factor $\delta \geq \frac{1}{1+m}$, higher discount factor that approaches $\frac{1}{2}$ when $m\rightarrow 1$ and $1$ as $m\rightarrow 0$</li>
      <li>Monitoring gets worse if the group gets bigger</li>
      <li>Exclusion also works with imperfect monitoring</li>
    </ul>
  </li>
  <li>
<strong>Folk Theorem</strong>: Cooperation is possible with large discount factors
    <ul>
      <li>To prove Folk theorem, there are three parts
        <ul>
          <li>Identify harshest punishment (minmax)</li>
          <li>Identify what payoffs are possible that are better than the harshest punishments (include mixtures)</li>
          <li>Show that the latter can be sustained with high enough discount factors</li>
        </ul>
      </li>
      <li>Individually rational profiles will have a reward/punishment from the minmax punishment
        <ul>
          <li>Coordination on some point $x$, where a player will get $z$ from defecting and $y$ in all subsequent periods, requires a discount factor $\delta\geq\frac{z-x}{z-y}$</li>
        </ul>
      </li>
      <li>This can be rewritten as $\frac{\delta}{1-\delta}(x-y) \geq z-x$ which represents the future sum of discounted rewards vs. the defection benefit today
        <ul>
          <li>As $\delta\rightarrow 0$, LHS becomes 0, so no cooperation</li>
          <li>As $\delta\rightarrow 1$, LHS becomes infinity</li>
        </ul>
      </li>
      <li>There must exist a “sweet spot” $\delta^* \equiv \frac{z-x}{z-y} \in [0,1]$ to sustain cooperation, proving Folk Theorem</li>
      <li>Does not guarantee coordination</li>
    </ul>
  </li>
  <li>Self-enforcing cooperation has various requirements
    <ul>
      <li>Infinite repetition</li>
      <li>Sufficient detection of defectors (monitoring)</li>
      <li>Strong punishment for defectors (minmax, Nash reversion)</li>
      <li>Punishments that are credible and not too costly for the punisher</li>
      <li>Large future rewards from cooperation (high discount factors)</li>
      <li>If any of these requirements are not met, then Homo Economicus will not cooperate</li>
    </ul>
  </li>
  <li>Because there are various trigger strategies, a failure to coordinate on the cooperation-sustaining strategy will result in non-cooperation</li>
</ul>

<h1 id="unit-2">
<a class="anchor" href="#unit-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Unit 2</h1>

<h2 id="experimental-economics">
<a class="anchor" href="#experimental-economics" aria-hidden="true"><span class="octicon octicon-link"></span></a>Experimental Economics</h2>

<ul>
  <li>
<strong>Experimental economics</strong> is the practice of designing and carring out experiments to test economic theories of behavior
    <ul>
      <li>Requires a large sample of subjects, random assignment, control, and replication</li>
      <li>
<em>Controlled</em> experiments are ones where the experimenter assigns treatments; <em>uncontrolled</em> experiments are observational with unassigned treatments</li>
    </ul>
  </li>
  <li>Economics experiments use simple design, consistent instructions, neutral language, monetary incentive (for utility functions), no deception</li>
</ul>

<h3 id="experimental-results">
<a class="anchor" href="#experimental-results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Experimental Results</h3>
<ul>
  <li>One-shot
    <ul>
      <li>Ridinger and Mcbride (2024): 49% of UCI students choose to cooperate in the one-shot PD game (typically 40-50% for American college students)</li>
      <li>Ensminger (2004): Kenyan men choose to contribute Linear Public Good Game, but HE does not contribute anything (typically 40-60% for American college students)</li>
      <li>Forsythe et al (1994): Many American college students share in the Dictator Game, and they share even more with hypothetical money</li>
      <li>These results show that experimental subjects will cooperate and give at higher rates than Homo Economicus</li>
    </ul>
  </li>
  <li>Sequential
    <ul>
      <li>Forsythe et al (1994): Offers are larger in the Ultimatum Game than in the Dictator Game because recipients will reject lower offers despite it always being better to accept
        <ul>
          <li>Oosterbeek et al (2004): Subjects around the world reject lower offers</li>
        </ul>
      </li>
      <li>In sequential PD, more first movers cooperate than in one-shot simultaneous PD, and a plurality of second movers are conditional cooperators</li>
      <li>These results show that econd movers are willing to pay a cost to reward a first-mover cooperator and/or punish a selfish first-mover
        <ul>
          <li>Ridinger and Mcbride (2024): First movers will cooperate if they expect conditional cooperation</li>
        </ul>
      </li>
      <li>These results also show that subjects will cooperate at higher levels to gain a reward or avoid a punishment</li>
    </ul>
  </li>
  <li>Repeated
    <ul>
      <li>Dal Bo (2006): In PD, subjects are more likely to cooperate when there are more rounds, either in indefinite horizon or finite horizon</li>
      <li>Matches inuition of Folk Theorem, but also shows that subjects don’t perform backwards induction (always defect) like Homo Economicus</li>
      <li>Lugovskyy et al (2017): In the Linear Public Good Game, most people will cooperate in early rounds and then start to contribute less regardless of whether or not the game is finite or indefinite
        <ul>
          <li>Cooperation tends to decline within repeated matches; declines faster in finite horizon games</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Contests
    <ul>
      <li>Chowdhury et al (2012): Subjects will either exert excessive or zero effort in a contest, contrasting HE who will only exert a medium amount of effort to avoid significant loss
        <ul>
          <li>Ranges from socially efficient or very socially inefficient</li>
          <li>Efforts stay at the same level over time</li>
        </ul>
      </li>
      <li>This shows that real humans are even less cooperative than Homo Economicus in contests</li>
    </ul>
  </li>
  <li>Differences in strategies can be ascribed to culture, gender, religion, etc
    <ul>
      <li>Shows that there is a lot of variation (heterogeneity) in individuals</li>
    </ul>
  </li>
  <li>General lessons
    <ol>
      <li>Humans care about money</li>
      <li>Humans care about more than just money because they cooperate at a higher rate than Homo Economicus</li>
      <li>Values differ across settings, i.e. Public Good Game vs. Contests</li>
      <li>Human cooperativeness depends on expected rewards and punishments</li>
      <li>Humans differ in how they trade off selfish and prosocial values</li>
      <li>Humans are often conditionally cooperative</li>
    </ol>
  </li>
</ul>

<h2 id="social-norms-and-rule-following">
<a class="anchor" href="#social-norms-and-rule-following" aria-hidden="true"><span class="octicon octicon-link"></span></a>Social Norms and Rule Following</h2>

<ul>
  <li>
<strong>Social norm</strong>: A behavioral rule in a specific community that defines acceptable and unacceptable behavior
    <ul>
      <li>Can either be <strong>prescriptive</strong> (do a certain action) or <strong>proscriptive</strong> (don’t do an action); defines moral restraint</li>
      <li>Social norms are <strong>deontic</strong>: individuals follow the rule as opposed to the consequence
        <ul>
          <li>People following social norms are NOT Homo Economicus because HE are consequentialist</li>
        </ul>
      </li>
      <li>Norm violation has both an external and internal punishment
        <ul>
          <li>Punishment can be conditional; if others are violating the norm, the punishment won’t feel as bad</li>
        </ul>
      </li>
      <li>Preference is to follow the norm, not the norm itself</li>
      <li>Norms can be formal (intentionally designed) or informal</li>
      <li>Norms can be conventional (small punishment, e.g. trends) or moral (unconditionally followed)</li>
      <li>Highlights the values of a community</li>
    </ul>
  </li>
  <li>
<strong>Socialization</strong>: The process of learning and adopting the norms of a community
    <ul>
      <li>Socialization comes from rewards and punishments from following or not following norms, leading to an individual internalizing and conforming to the norms</li>
      <li>
<strong>Primary socialization</strong> is the development of the ability to learn about norms and judge actions</li>
      <li>
<strong>Secondary socialization</strong> is the learning of norms of a specific community</li>
      <li>Cooperation rates will increase when people have internalized norms</li>
      <li>No other species has the capacity to internalize norms</li>
    </ul>
  </li>
  <li>Kimbrough and Vostroknutov (2016) used a traffic simulation to show that people are unwilling to disobey the rules to get a monetary benefit
    <ul>
      <li>Groups of rule followers were better able to sustain cooperation</li>
    </ul>
  </li>
  <li>McBride and Ridinger (2021) showed that fule following is conditional on other’s compliance
    <ul>
      <li>People who conformed to rules also gave the most in the dictator game</li>
    </ul>
  </li>
</ul>

<h3 id="homo-normist">
<a class="anchor" href="#homo-normist" aria-hidden="true"><span class="octicon octicon-link"></span></a>Homo Normist</h3>

<ul>
  <li>Norm compliance can be included in a utility function
    <ul>
      <li>Define acceptable and unacceptable strategies: $A_i \subseteq S_i$
        <ul>
          <li>Meaningful norm: $\empty \subset A_i \subset S_i$</li>
        </ul>
      </li>
      <li>Utilities are more than material; i.e. norms are included in the utility function
        <ul>
          <li>Material payoff: $y_i(s_i, s_{-i}) \in \mathbb{R}$</li>
          <li>Homo Normist preferences: $u_i(s_i, s_{-i}) \neq y_i(s_i, s_{-i})$
            <ul>
              <li>Has internalized penalty $u_i(s_i, s_{-i}) = y_i(s_i, s_{-i}) - \rho_i k_i$ if $s_i \notin A_i$</li>
              <li>$\rho$ is the community reference of accepttable behavior, $k$ is the individuals guilt</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Define community compliance reference
        <ul>
          <li>$\rho$ can be the compliance of other players (internal), rate of compliance in the larger community (external), and/or personal belief about compliance (subjective)</li>
          <li>Depends on the setting</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Homo Normist is both deontic and consequentialist; they compare the best acceptable strategy and the best unacceptable strategy
    <ul>
      <li>Leads to a tradeoff between rule following and maximizing material payoff</li>
    </ul>
  </li>
  <li>Homo Normist is experimentally proven and rational (because their choices are consistent)</li>
</ul>

<h2 id="one-shot-homo-normist-games">
<a class="anchor" href="#one-shot-homo-normist-games" aria-hidden="true"><span class="octicon octicon-link"></span></a>One-Shot Homo Normist Games</h2>

<ul>
  <li>In the Dictator Game, different norms can lead to the dictator sharing
    <ul>
      <li>The community reference for player 1 does not come from player 2 since player 2 has no action; it comes from people outside of the game</li>
      <li>Assuming that the total amount of money is 1, equality norm: $A_i = {0.5}$; full-sharing norm: $A_i = {1}$</li>
      <li>With more forced sharing, then players are required to have a higher norm salience or a greater community reference</li>
    </ul>
  </li>
  <li>The most preferred acceptable action will always be chosen out of the acceptable actions</li>
  <li>In the PD Game, the community reference comes from the other player (internal) because it is symmetric
    <ul>
      <li>Depending on the values of $k$ and $\rho$, the one-shot PD Game can become a Coordination Game
        <ul>
          <li>With common knowledge of the norm, then both players will know the other player will want to follow the norm, allowing for both cooperation and coordination</li>
        </ul>
      </li>
      <li>If one player is Homo Economicus or if one player has a low norm salience, then cooperation disappears</li>
      <li>With an external community reference, cooperation can become a NE</li>
    </ul>
  </li>
  <li>In the Ultimatum Game, both players will have norm salience, leading to cooperation
    <ul>
      <li>If $A_2 = \text{Accept if } s_1 &gt; 0.5$, then they will accept if $s_1 &gt; \min(0.5, \rho_2k_2)$
        <ul>
          <li>Player 1 will thus offer $s^*_1 = \min(0.5, \rho_2k_2)$ so they can maximize their payoff</li>
        </ul>
      </li>
      <li>This shows that the threat of punishment by a norm-following player can induce sharing from Homo Economicus</li>
    </ul>
  </li>
  <li>In the Sequential PD game, cooperation can still be sustained with player 1 being Homo Economicus
    <ul>
      <li>With norm-following preferences and an internal community reference, player 2 will likely conditionally cooperate, forcing player 1 to cooperate due to the unique SPE being $(C, CD)$</li>
      <li>With an external community reference, Homo Economicus will defect as player 1 because player 2 becomes an unconditional cooperator</li>
      <li>In general, conditional cooperation is better for cooperation</li>
    </ul>
  </li>
  <li>In the Linear Public Good Game, the socially efficient outcome of donating all income to the public good can only be achieved when norm saliences are large
    <ul>
      <li>Using an internal community reference, the norm salience needed for cooperation decreases as compliance increases</li>
      <li>This turns the game into a coordination game where the equilibria are to donate everything or donate nothing</li>
      <li>With large groups of people, people have heterogenous preferences, and one person’s defection can undermine the group’s cooperation
        <ul>
          <li>Increasing the size of the group increases the required norm salience</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="general-takeaways">
<a class="anchor" href="#general-takeaways" aria-hidden="true"><span class="octicon octicon-link"></span></a>General Takeaways</h3>

<ol>
  <li>The community reference (internal or external) depends on the setting</li>
  <li>Norms can prescribe costly rewards and punishments</li>
  <li>Internalized norms can make cooperation an equilibrium in a one-shot game</li>
  <li>Normist preferences can create a coordination incentive</li>
  <li>The exact collection of preferences can have have a large effect on the equilibrium (i.e. two Homo Normist vs. one Homo Normist and one Homo Economicus)</li>
  <li>Norms of conditional cooperation are especially effective</li>
  <li>Acceptable actions do not have to be NE in the base material game</li>
</ol>

  </div><a class="u-url" href="/college-notes/econ113/lecture/spring25/markdown/2025/04/05/econ113-lecture.html" hidden></a>
</article>

      </div>
    </main><link id="fa-stylesheet" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css">

<footer class="site-footer h-card">
  <data class="u-url" value="/college-notes/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
      </div>
      <div class="footer-col">
        <p>Site to document notes for various classes</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
    <a rel="me" href="" target="_blank" title="">
      <span class="grey fa-brands fa- fa-lg"></span>
    </a>
  </li><li>
    <a rel="me" href="" target="_blank" title="">
      <span class="grey fa-brands fa- fa-lg"></span>
    </a>
  </li>
  <li>
    <a href="https://tonyhieu.github.io/college-notes/feed.xml" target="_blank" title="Subscribe to syndication feed">
      <svg class="svg-icon grey" viewbox="0 0 16 16">
        <path d="M12.8 16C12.8 8.978 7.022 3.2 0 3.2V0c8.777 0 16 7.223 16 16h-3.2zM2.194
          11.61c1.21 0 2.195.985 2.195 2.196 0 1.21-.99 2.194-2.2 2.194C.98 16 0 15.017 0
          13.806c0-1.21.983-2.195 2.194-2.195zM10.606
          16h-3.11c0-4.113-3.383-7.497-7.496-7.497v-3.11c5.818 0 10.606 4.79 10.606 10.607z"
        />
      </svg>
    </a>
  </li>
</ul>
</div>

  </div>

</footer>

</body>

</html>
